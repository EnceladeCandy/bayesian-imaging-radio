{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.func import vmap, grad\n",
    "from tqdm import tqdm\n",
    "from torch.distributions import MultivariateNormal\n",
    "sys.path.append(\"..\\\\\")\n",
    "plt.style.use(\"dark_background\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "from score_models import ScoreModel, NCSNpp\n",
    "import json\n",
    "file = open(\"../../score_models/ncsnpp_probes_g_64_230604024652/model_hparams.json\")\n",
    "model_hparams = json.load(file)\n",
    "sigma_min, sigma_max = model_hparams[\"sigma_min\"], model_hparams[\"sigma_max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_probes_g_channel(img, inv_link = False):  # channel 0\n",
    "    img = torch.clamp(img, 0, 1.48)\n",
    "    \n",
    "    if inv_link:\n",
    "        img = 2 * img / 1.48 - 1.\n",
    "    return img\n",
    "\n",
    "def link_function(x):\n",
    "    # Mapping from (-1, 1) to (0, 1)\n",
    "    return (x + 1)/2\n",
    "\n",
    "def inv_link(x): \n",
    "    return 2 * x - 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the Variance Exploding SDE\n"
     ]
    }
   ],
   "source": [
    "score_model = ScoreModel(checkpoints_directory=\"../../score_models/ncsnpp_probes_g_64_230604024652\")\n",
    "\n",
    "x = torch.load(\"model_prior_sample.pt\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing for the DFT matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft(x): \n",
    "    return torch.fft.fft2(x, norm = \"ortho\")\n",
    "\n",
    "def ift(x): \n",
    "    return torch.fft.ifft2(x, norm = \"ortho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4194304.00 GiB (GPU 0; 4.00 GiB total capacity; 823.93 MiB already allocated; 1.13 GiB free; 998.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m img_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      2\u001b[0m sigma_likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-5\u001b[39m\n\u001b[1;32m----> 3\u001b[0m dist_likelihood \u001b[38;5;241m=\u001b[39m MultivariateNormal(loc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m img_size\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, device \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdevice), covariance_matrix\u001b[38;5;241m=\u001b[39msigma_likelihood \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m eta \u001b[38;5;241m=\u001b[39m dist_likelihood\u001b[38;5;241m.\u001b[39msample([])\n\u001b[0;32m      6\u001b[0m ft_x \u001b[38;5;241m=\u001b[39m ft(x)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4194304.00 GiB (GPU 0; 4.00 GiB total capacity; 823.93 MiB already allocated; 1.13 GiB free; 998.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "img_size = x.shape[-1]\n",
    "sigma_likelihood = 1e-5\n",
    "dist_likelihood = MultivariateNormal(loc = torch.zeros(2 * img_size**2, device = x.device), covariance_matrix=sigma_likelihood ** 2 *torch.eye(2 * img_size**2, device = x.device))\n",
    "eta = dist_likelihood.sample([])\n",
    "\n",
    "ft_x = ft(x).flatten()\n",
    "ft_x = torch.cat([ft_x.real, ft_x.imag])\n",
    "y = ft_x + eta\n",
    "#x_flat = link_function(x.flatten())\n",
    "#y = x_flat + 0.1 * torch.randn_like(x_flat)\n",
    "y = preprocess_probes_g_channel(y, inv_link = False)\n",
    "y_dim = len(y)\n",
    "\n",
    "print(y.shape)\n",
    "# Checking if I do something wrong\n",
    "fig, axs = plt.subplots(1, 3, figsize = (8, 4))\n",
    "for i in range(len(axs)): \n",
    "    axs[i].axis(\"off\")\n",
    "\n",
    "axs[0].imshow(x.reshape(-1, img_size).cpu(), cmap = \"hot\")\n",
    "axs[1].imshow(y.reshape(-1, img_size).cpu(), cmap = \"hot\")\n",
    "\n",
    "y_rep = y[:img_size**2] + 1j * y[img_size**2:]\n",
    "im = axs[2].imshow(ift(y_rep.reshape(img_size, img_size)).real.cpu(), cmap = \"hot\")\n",
    "plt.colorbar(im)\n",
    "# fig, axs = plt.subplots(nrows = 1, ncols = 2, figsize = (8, 4))\n",
    "\n",
    "# for i in range(len(axs)): \n",
    "#     axs[i].axis(\"off\")\n",
    "\n",
    "# axs[0].imshow(y.reshape(64,64).squeeze().cpu(), cmap = \"magma\")\n",
    "# axs[0].set_title(r\"Observation $\\mathbf{y}$\")\n",
    "\n",
    "# im = axs[1].imshow(x.squeeze().cpu(), cmap = \"magma\")\n",
    "# axs[1].set_title(r\"Ground-truth $\\mathbf{x}$\")\n",
    "# plt.colorbar(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002, device='cuda:0')\n",
      "tensor([[-1.8922e-03,  5.3076e-04, -7.2963e-04,  ...,  2.6589e-04,\n",
      "         -2.4864e-03, -1.3411e-03],\n",
      "        [ 1.1824e-03,  9.5197e-04,  6.9952e-04,  ..., -3.1843e-03,\n",
      "          3.0137e-03,  9.6435e-05]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def sigma(t): \n",
    "    return sigma_min * (sigma_max/sigma_min) ** t\n",
    "\n",
    "\n",
    "def model(x):\n",
    "    x = link_function(x)\n",
    "    x = ft(x.reshape(img_size, img_size)).flatten()\n",
    "    x = torch.cat([x.real, x.imag])\n",
    "    return x\n",
    "\n",
    "def logprob_likelihood(x, sigma): \n",
    "      D = x.shape[-1]\n",
    "      val = -torch.sum(x**2, axis = -1)/(2*sigma**2) - D/2 * np.log((2*torch.pi))- D * torch.log(sigma)\n",
    "      return val.squeeze(0) # needs to be without diemensions   \n",
    "\n",
    "def score_likelihood(x, t): \n",
    "    return vmap(grad(lambda x, t: logprob_likelihood(y -model(x), (sigma_likelihood ** 2 + sigma(t)** 2)**0.5)))(x, t)\n",
    "\n",
    "\n",
    "#torch.manual_seed(0)\n",
    "def score_posterior(x, t): \n",
    "    return score_model.score(t, x.reshape(-1, 1, img_size, img_size)).flatten(start_dim = 1) + score_likelihood(x, t)\n",
    "\n",
    "x = torch.randn([2, img_size ** 2]).to(device) \n",
    "t = torch.ones([2]).to(device)\n",
    "\n",
    "print((torch.sum(score_likelihood(x, t)**2))**0.5)\n",
    "print(score_posterior(x, t))\n",
    "#score_model.score(t, x.reshape(-1, 1, img_size, img_size)).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [00:23<00:00, 20.92it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def g(t): \n",
    "    return sigma(t) * np.sqrt(2 * (np.log(sigma_max) - np.log(sigma_min)))\n",
    "\n",
    "\n",
    "def pc_sampler(num_samples, num_pred_steps, num_corr_steps, score_function, snr = 1e-2, img_size = 28): \n",
    "    t = torch.ones(size = (num_samples, 1)).to(device)\n",
    "    x = torch.randn([num_samples, img_size ** 2]).to(device)\n",
    "    dt = -1/num_pred_steps\n",
    "    with torch.no_grad(): \n",
    "        for _ in tqdm(range(num_pred_steps-1)): \n",
    "            # Corrector step: (Only if we are not at 0 temperature )\n",
    "            gradient = score_function(x, t)\n",
    "            for _ in range(num_corr_steps): \n",
    "                z = torch.randn_like(x)\n",
    "                grad_norm = torch.mean(torch.norm(gradient, dim = -1)) # mean of the norm of the score over the batch \n",
    "                noise_norm = torch.mean(torch.norm(z, dim = -1))\n",
    "                epsilon =  2 * (snr * noise_norm / grad_norm) ** 2\n",
    "                x = x + epsilon * gradient + (2 * epsilon) ** 0.5 * z * dt  \n",
    "\n",
    "        \n",
    "            # Predictor step: \n",
    "            z = torch.randn_like(x).to(device)\n",
    "            gradient = score_function(x, t)\n",
    "            drift = 0\n",
    "            diffusion = g(t)\n",
    "            x_mean = x - diffusion**2 * gradient * dt  \n",
    "            noise = diffusion * (-dt) ** 0.5 * z\n",
    "            x = x_mean + noise\n",
    "            t += dt\n",
    "    return x_mean\n",
    "\n",
    "def euler_sampler(num_samples, num_steps, score_function, img_size = 28): \n",
    "    t = torch.ones(size = (num_samples, 1)).to(device)\n",
    "    x = sigma_max * torch.randn([num_samples, img_size ** 2]).to(device)\n",
    "    dt = -1/num_steps\n",
    "    with torch.no_grad(): \n",
    "        for _ in tqdm(range(num_steps - 1)): \n",
    "            z = torch.randn_like(x).to(device)\n",
    "            gradient = score_function(x, t)\n",
    "            drift = 0\n",
    "            diffusion = g(t)\n",
    "            x_mean = x - diffusion**2 * gradient * dt  \n",
    "            noise = diffusion * (-dt) ** 0.5 * z\n",
    "            x = x_mean + noise\n",
    "            t += dt\n",
    "    # DONT FORGET TO APPLY THE LINK FUNCTION\n",
    "    return link_function(x_mean)\n",
    "\n",
    "\n",
    "#samples = pc_sampler(num_samples = 1, num_pred_steps = 500, num_corr_steps = 20, snr = 1e-4, score_function = score_posterior, img_size = img_size)\n",
    "samples = euler_sampler(num_samples = 1, num_steps = 500, score_function = score_posterior, img_size = img_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0340, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdAAAAGFCAYAAABNHqJEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApJ0lEQVR4nO3df4xeZfnn8c/UTkvoPhNDa+k4dBB0/QL6jTaFRGvlD5OBtYkYXOiyYIJdCNjij4BZTQmp+KMNCVAbMFiiRX5kWZm4poSVLmOQ7Nb+MN8purEiRiy1pbQDRevM1nY6M539A1sc574enus815nnnDnvVzJ/cHN6n/uc58f93Ne5znXaJI0LAAC4zGj1AAAAKCMmUAAAMmACBQAgAyZQAAAyYAIFACADJlAAADJgAgUAIIOZrR4AAGB6mD17tmbNmhXS14kTJzQ8PBzSV14ankDHx/9z+n9c/t+Tzev7Jrc9b/Q9ZLT/zWgfS7SNGNta7RZrSZ56S7Q793nEaE8d/wln3yeN9tS5sni2bZV3tHoAwTzn3Dr2qNfNc26tba3PT2p76/NzhtFeM9rPMtpTn9njxrZWu/fcpo7TOlfW8VvHeWaibYmx7ar/mG5v+x/GPwgwe/ZsHT9unUm/gwcP6rzzziv0JEoIFwDQtKiV5ymdnZ3hfUYjhAsACDQa1E/xp6fijxAAUCLVmUAJ4QIAkEHxp3gAQIlErUCLr/EJ9Pp0tu1gIttWkgYSbd4MUktqe2+2nJXlamXMpcZu7dM6nqNGe6of7znxKnrGbZ7Ztnlns3r69hyn9/3myYiNEpHJa7XPMdrfY7Snslb/bGx7yGi38j8j3ivW6+PpO/U9K0kncsy2fXvVmUAJ4QIAkAEhXABAoDFJ40320RYxkNwxgQIAAo2qKhMoIVwAADJgBQoACFSdFWjDE+j3H023/8nYPpXV5q3X6m33bGuNxTNGa1srwzeiXm2UiOzPCN6M2IgMUm/frXh9UlnfVu1Uq9iZ9T6MOLfe0JVne2vb2Ub7O432dyXarM+gVY/bunPA856ICvOlxrLf2PabQfvMhgkUAIAMqpNExDVQAAAyYAUKAAg0puZLwZRjbccECgAINCom0H/yS6PdusieeqyqN6nB4nmgtjcRyZPo4+3Dk1xUpFJ7eZZ+yzNZKG+pMUYlKKUShs519m2VrTtitHv6tt7jeb5ufzPaDxjtqc9b1IOzLRHH70lwtL5TXg0YB94eK1AAQCBWoAAAZFCdCbQcowQAoGBYgQIAAo2p+avKZciCYAIFAIQaVfMTaLOFGKZGwxOolQFnnaZUtpv3gdqe7a1xWH1YPFm7rSjN572yUKTydCmtKOXn7SPPfVrHmXoY9EXGtu8x2v+n0W6VrfPI89qP9R63MmhfN9pTx+ntOyLbOKJsqJTOuLVeh2avQKIxrEABAIFYgQIAkAETKAAAGVRnAuU2FgAAMmAFCgAINKY3V6HTX8MT6FGj3ZNJ5qmbW297T0asxZsB58n89dbIzZMnmzXveqAR9YSt9lQoJe87ySIe7G5JvfdfMba1at5an9mi836urDsEhh19eMdivbdS7d4wn2ef1nek9+6DWKOqygRKCBcAgAwI4QIAAlVnBcoECgAIVJ0JlBAuAAAZsAIFAASqzgq04QnUkxErxWStetq94/Nmf3oySMsgNfYiPf/Ae25bEUrJ83ylMtNfdI7D+5ko0uufYh2PlW08y9F3Gc5JqhaupbWhxYjbWNoiBpI7VqAAgEARjzMrx9XFcowSAICCYQUKAAgUcQ2UEC4AoHKYQCfJM4nIW1YvNRZvxN27z4jygZY8y255kiBakUhh9d2Kh5Vb8nxosackXFTZNs/rmec1Huu1tPbpTZZKvT5RxxPxvedJcvKOo8wJjmXCChQAECgiC7cc6TlMoACAQBEh3HJMoOUYJQAABcMKFAAQqDorUCZQAEAgJtBJvJl+ntJ3VokqT3Zd1EOs88xe82TM5Zm55xWVnRuRzdsesD/vR9PzEG/PtvW2T8m7rJznvESMxZuBbX1P5Fmyz/t6euT5XVOO6af8OM8AgECjQX8+K1eu1J49e3Ts2DH19/dr6dKldbe/9tpr9etf/1pHjx7Vq6++qoceekhnnXWWa59MoACAQKduY2nmz7c+X758uTZs2KC1a9dq0aJF2rp1q7Zs2aKFCxcmt//Yxz6mRx99VJs2bdIHPvABXX311brkkkv0gx/8wLVfJlAAQKCpX4Hedttt2rRpkzZt2qQXX3xRt956q/bv36+VK1cmt//IRz6ivXv36v7779fevXu1bds2Pfjgg7r44otd+2UCBQAUUq1Wm/A3a9bkK97t7e1avHix+vr6JrT39fVpyZIlyX63b9+uc845R5/85CclSfPnz9dVV12ln/70p67xMYECAALFrUAPHDigwcHB03+rV6+etLd58+Zp5syZGhgYmNA+MDCgBQsWJEe4Y8cOXXfddXriiSd04sQJDQwM6MiRI/riF7/oOtKGs3Ajai5G1Y6NqEtb9FqRrci2tbTiocIR+/Rmvlrbe35len+RFukX7FS/zlHZ3Z7vplZk21qsvj0Z+FHfqbEibmN585Xq6urS0NDQ6dbh4WHzX4yPj0/477a2tkltp1x44YW677779M1vflPPPPOMOjs7dffdd2vjxo268cYbGx4l94ECAAppaGhowgSacvjwYY2Ojk5abc6fP3/SqvSU1atXa9u2bbrnnnskSb/5zW909OhR/eIXv9Add9yhQ4cONTS+Iv0ABgCU3tRm4Y6MjGjXrl3q6emZ0N7T06Pt27cn/82ZZ56pkycnrt/Hxt7cZ1tb449SYwUKAAgUEcL1/fv169frscceU39/v3bs2KGbbrpJ3d3d2rhxoyRp3bp16urq0vXXXy9Jeuqpp/T9739fn//850+HcDds2KBf/vKXOnjwYMP7ZQIFAJRab2+v5s6dqzVr1qizs1O7d+/WsmXLtG/fPklSZ2enuru7T2//yCOPqFar6Qtf+ILuvfdeHTlyRD//+c/1ta99zbXfNknpq6z/xKrpEJFE5C3ll2qPKDVYrz0lKnEpNfZWJO604oHaeYpKIqqKPF/n1Ln1PEzc6qPe9s1um2WfnuP0lKWUYhIL/3dAH5ZarabBwUFJX5J0vMnezpB0nzo6Ot72GmgrTWktXC/ri85TO9YSUTs3KpPX+0HyKGaW3ltaMWmVYaIs+o+WPM9h0TPko3hfY2uhkdLaz/3Uh3BbpQzfJQAAFA7XQAEAgcbUfByhHHEIJlAAQKBTt7E020fxMYECAAJxDRQAANSRWy3ciGxWT9/eBX/Rs1MteY47KvPTe/tIURQ989Xi/RU83W7j8RxP1K1aEe/lqDsHIvqOVZ0VKCFcAECg6kygZf3RCQBAS7ECBQAEqs4KlAkUABCI21gmsUr5RdSO9dSI9e7TK+J4IuLiRU+4ySLivEx1vdbpqCjHWYbay94xRnxuy5qEV0WsQAEAgQjhAgCQQXUm0KJEcwAAKBVWoACAQNVZgTKBAgACkYU7ibdkn+eh197s3Dwzfz2i4t95ZtflmemYZ/w/z/FZfbciK9TTd95fKZ7+vecwQisyYr1SY/GOoxxTRz3VWYFyDRQAgAwI4QIAAlVnBcoECgAIVJ0JlBAuAAAZsAIFAASqzgq06Vq4llQmWZ4ZsXn27RWRdReV+VmkbNupHot3f9b2eY67FQ+3jvhMeDNiIx4GnWf2tPd1iMhYnr61batzGwshXAAAMiCECwAINKbmV5DlWIEygQIAAlXnGighXAAAMmAFCgAIVJ0VaNO1cC2pDLOI2rZ582TjRWXR5Vlrtay8oZHUOfSe14h9euX52lvvz4j6uxEZsd7PfcRYvOc7z+zc6YsJFACADLiNBQAA1MEKFAAQiBAuAAAZMIFO0oqHwnr2mXfEfPqW3XpL3g+gjrhe4Cm3F5UUNN2SvCKSi7yKckXLO46yluEr+vimC1agAIBArEABAPAbDyrl1xYxmHyRhQsAQAasQAEAcSpUYYYJFAAQJypjbDpNoFFltyIUJaOvKiIeWGyJynxNXYvw9u3NQs5T6pxb47Medh9Rti7q2D1l9VrxXdOKh3Xnie/IqcEKFAAQp0KzNxMoACBOhW5CZQIFAMSp0AqU21gAAMiAFSgAIA4h3MZZq/WIc5hnJKAqr3Ge9We9+/T04x33rIBxRIy7FdnnUdmsHhE1ZYsU6SvSuY3Q0vGdlDTeZB8lqEIkEcIFACATQrgAgDhjqswKlAkUABCHEC4AAKiHFSgAIA4h3MmKnm0blVWbZ93XPBUp2zaqf08fnlq47UH79Gxrva+s9qKEhqqSrW6JyM7Ns85uIbOBKzSBFuVzCgBAqRDCBQDEqVASERMoACBOhUK4TKAAgDjjav7ieUkuLpZkmAAAFEvDK1DvD4oiZdZ6FD3bthUiasTW68fTt5VBm2q3+oiqhet5j3v7PuHoIyoTMzUW6zPYihqx3u+DPFcHnuP0nhPP9oXMkh5T8wNrNgQ8RQjhAgDiVGgCJYQLAEAGrEABAHFOqqCx5XhMoACAOBUK4TZdyi9CRX6stEQrkqIiSt9ZyUKexKCIPiT7OoenJKD1Hk8lC1ljybvMZKp/69hbkVToHUuq3dtH1PFPtUKW+JuGWIECAOJUaAVKEhEAIM7JoD+nlStXas+ePTp27Jj6+/u1dOnSutvPmjVL3/72t7V3714dP35cL730klasWOHaJytQAECpLV++XBs2bNCqVau0bds23XzzzdqyZYsuuugi7d+/P/lvent7dfbZZ+uGG27QSy+9pPnz52vmTN+U2KYGF8tnu7r1Kfr1hDKIKnYQ0XeejxzzbJ/3NVAP7zXQkUSb95GCEdtH7bMoORRVvwY6kOM+a7WaBgcHpX/rkMaGmuvsHTXpkkF1dHRoaOjt+9q5c6eef/55rVq16nTbCy+8oM2bN+v222+ftP3ll1+uH/3oRzr//PP1l7/8JfMwCeECAOIEhnBrtdqEv1mzZk3aXXt7uxYvXqy+vr4J7X19fVqyZElyiFdccYX6+/v11a9+Va+88op+//vf6+6779YZZ5zhOtSmQ7ieX25F/9VWdXmuNK3tvX1HlPLzrkzzXIFGbJ/3w+QjFOUh0Xm+Dl7TNlN2TGEHd+DAgQn/feedd+ob3/jGhLZ58+Zp5syZGhiYuL4eGBjQggULkv2ef/75Wrp0qY4fP64rr7xS8+bN0wMPPKCzzjpLN9xwQ8Pj4xooAKCQurq6JoRwh4eHzW3HxydejWxra5vUdsqMGTM0Pj6u66677s2ws6TbbrtNP/7xj3XLLbfo+PHjDY2PCRQAECdwBTo0NPS210APHz6s0dHRSavN+fPnT1qVnnLw4EEdOHDg9OQpSb/73e80Y8YMnXPOOXrppZcaGh/XQAEAcab4NpaRkRHt2rVLPT09E9p7enq0ffv25L/Ztm2b3v3ud2vOnDmn297//vdrbGxMr7zySsP7ZgIFAJTa+vXrdeONN2rFihW64IILtH79enV3d2vjxo2SpHXr1umRRx45vf3jjz+uN954Qz/84Q914YUX6uMf/7juvvtuPfTQQw2HbyVCuACASIEh3Eb19vZq7ty5WrNmjTo7O7V7924tW7ZM+/btkyR1dnaqu7v79PZHjx5VT0+P7r//fvX39+uNN95Qb2+v7rjjDtd+G74P9F2ubosj7/qhU80bMvAcp6e2a73tI+rVetsnJ7fb21rnMNVHve09GZqe+z0lKfUb2NrWe6+mpx9v3xbr+D3KkMVf9MzaKbkP9GdB94H2NH4faKsQwgUAIANCuACAOONqPlxQkqUdEygAIE7ENdC2iIHkryTzPAAAxcIKFAAQJ+PjyCb1UQKFmECLUoNTKk7Wbt6hAU//3mP31JT11t+1MmVTGbdWWWhv9rCHlW1q9W19T6S29z4BpRU8n58yjLvoCjnPVCiEW4gJFAAwTVRoAuUaKAAAGbACBQDE4RooAAAZEMIFAAD1TOkKtBWZbmXIrov4FRORKevJno3a3sqq9WbQprb39uGtBWzVlE3x1qWNyFrN873vfc/y2W9eSaKabw602ZNfkqUdIVwAQJwKXQMtyTwPAECxsAIFAMSJSCIqydKOCRQAEKdCIdymJ9CiXKi3Elq84/P0U4aHcuf5Q87z4GwpnaRjjc+TLGS1n+ns2/se8iT6WMeZZwJZnt9BeX7uy/DdWfQxFuV7ebpjBQoAiEMIFwCADJhAAQDIoELXQEsyzwMAUCysQAEAcSIqEZUhQ1MBE2hU9muz8sy2tbb3Pnw7z4xLb9+pfqJK9kWU8vOW20tl3M5x9mGN24omHXf07S3lV5Tsaet4rHFbDxQnK7RCCOECAIB6COECAOJEZOGWJGTBBAoAiFOhCZQQLgAAGbACBQDEqVASUcMTaElW1Lkpay3ciDF6a956sna9dWk9NXKtWrhWdq4Vjkll21qs7NRhRx+WqJq31jl8V6Kty9j2gNG+x2hPjTHqO6XK302FPHZCuAAAoB5CuACAOBVagTKBAgDijKv5a5jjEQPJHxMoACBOhVagXAMFACADVqANishmtaIaRfkVk3dWsaf+rifbVkpn3KaySiXpLKPden2OOLY/amwb8RpH1Xu2zsuDibYFA8bGl6WbL/+/6XYrO9cjYlFSpLsj8lxktfQOAW5jAQAgA0K4AACgHlagAIA4FVqBMoECAOJwDXT68F5Mz/PiuydenudDuaP68T6AO9XuLdlnleF7Z6JtobHtvxrt1o9eIy9GQ4m2qHJ7nu29D3avGe0L7ks0zjduyPv13GTzu9r+nGz/k7HPPLXiO7goC6eijGO6m/YTKABgChHCBQAgg5NqfgIsSQiXLFwAADJgBQoAiEMSEQAAGXANtHGeDEBvtmCeijSWCN6HW3u29WbbesrzWdm23vZUdu6/GNv+61Ljf6TSaiUdKkh5OutHufe7xqrO929fmtx2ySVt6Y0/lW5+1ejbetB40U2374kpUaEVKNdAAQDIgBAuACAOIVwAADKo0ARKCBcAgAxYgQIA4lQoiajhCTRiRe3NXMszAy6ij6jleysy+iKyc/PM/I3I8LUevm12ciTd/Ddj8xOJNivb1HovezJrvX1Y7W8Y7f810Xb2R9Pbpive2hm+qbFHZRVHfNd691mUCGMhs4SpRAQAAOohhAsAiFOhJCImUABAnApdAyWECwBABqxAAQBxCOFOVvRM0bxFLNU9x+OtP+vNWs1TxFi8r/3xRJtVq/Yd/yfd/rqx/X6jPZWdm8rMlfy1YD1ZuBbvPlPHf8jY1hqLtc+i18KNukNgqlnjbun4KhTCZQUKAIhToRUo10ABAMiAFSgAIE6FVqBMoACAOONq/hrmeMRA8kcIFwCADEq5Ai1Sdm5K0cdnsX5NteJXljfLcyjRZmXhWtm2qT4kOxP1aKJt2NjWm53r+QHvrb/rqambZ43YMtS8LauWfgcRwgUAIIMKTaCEcAEApbdy5Urt2bNHx44dU39/v5YuXdrQv1uyZIlGRkb0q1/9yr1PJlAAQJyTQX8Oy5cv14YNG7R27VotWrRIW7du1ZYtW7Rw4cK6/66jo0OPPvqonn32Wd8O/44JFAAQZyzoz+G2227Tpk2btGnTJr344ou69dZbtX//fq1cubLuv3vwwQf1+OOPa8eOHb4d/t2UXgP1lp1qxYXwVvyiSO2zrIlIUsw5tN4TqZJ9Ujqhx3LE2fdfjfZUKT+rDyvRx0ou8jys2+J9ALenD0tEok+eVdzKWrKvqmq12oT/Hh4e1okTEz8d7e3tWrx4se66664J7X19fVqyZInZ9+c+9zm9973v1Wc/+1ndcccdmcbHChQAECcwhHvgwAENDg6e/lu9evWk3c2bN08zZ87UwMDAhPaBgQEtWLAgOcT3ve99uuuuu3TddddpbCz7zySycAEAcQKzcLu6ujQ09NYNZsPD1o1i0vj4xOoLbW1tk9okacaMGXr88cf19a9/XX/4wx+aGiYTKAAgzkk1P4H+fQU6NDQ0YQJNOXz4sEZHRyetNufPnz9pVSq9GRa+5JJLtGjRIn33u9+V9OakOmPGDI2MjOiyyy7Tc88919AwmUABAKU1MjKiXbt2qaenR5s3bz7d3tPToyeffHLS9oODg/rgBz84oW3VqlX6xCc+oauuukovv/xyw/tmAgUAxGnB80DXr1+vxx57TP39/dqxY4duuukmdXd3a+PGjZKkdevWqaurS9dff73Gx8f129/+dsK/f+2113T8+PFJ7W8ntwnUk+1W1mzbPMcdlZnsfQC3h3UOI7I8rT6s9lRGrJW1ah27tf2g0Z7KuLWyar3H4xGVKerpxzvuiDFGvN8s3s9b0bNzq1bKr7e3V3PnztWaNWvU2dmp3bt3a9myZdq3b58kqbOzU93d3U0OarI2NVj3/ixnx0W/DaNIE6hnLN4Jsd2xvTUOq48zjPZZRvtsRx9znPtMjdFz7JJ/Ak1N2tbtNFbqg3Xbi+c2Fm8tXGvCSW0fcStMvX48fTOBNs4at1UHOkKtVtPg4KD0sQ7paP3rlm9rTk3aNqiOjo63vQbaSoRwAQBxKlQLlwkUABCnBddAW4VCCgAAZMAKFAAQhxBu81LHX/TEorxFJAt5+y5SneFUVMaT0CLZWa4p3tqxVt+eBCBvzVtPko73XHm3T7W3ItvWEjEWauFOAUK4AACgHkK4AIA4gaX8io4JFAAQh2ugAABkwDVQAABQT8Mr0KJn0Ob9S8Bz/HmOJaoWboSIrEgrUuOtY2uVxGt0HPX6sMbiycKNaC9JVKswivKdlWc5wKIc4wSEcAEAyKBCEyghXAAAMmAFCgCIU6EkIiZQAEAc7gOdWkWKIxfyovw05k0iiuAtt+dJ9LESkTzl86z2PEv25a0o34eteO5nkcppIlYhJlAAwDRBCBcAgAzIwgUAAPWwAgUAxKnQCpQJFAAQh2ug+WhFvDjPTLeo44kYo/V+82QXWscT9dDrWYk2b7ZtnlmReZbbs86h53si72xbz1iKtEDwZLlGlcL0HH/lsm0rtALlGigAABkQwgUAxKnQCpQJFAAQp0LXQAnhAgCQAStQAECYqOhrGZKvmp5Ai7KELcPJtqTecN7jsV4HT4ZiRCavd3vvh83zoG1r26h9prKNrXPoHUuel4DyzLZtReStFZ/9Mn/f5K1KE2hR5j8AAEqFEC4AIExJ8n9CMIECAMKU5A6UEIRwAQDIgBUoACAMIdyEiKVqVDanh7e+63Sr1xvBen28mb+ePrw8dWk9fdTrJ7V9VL3aVD8RfdQTEXrzft6KIs/voChlCRdWKYTLChQAEOakpPEm+2iLGMgUKMuPGgAACoUVKAAgTJVWoEygAIAwY6rOBEoIFwCADJpegXqy1LyzdZ6zO78cmmdlrXpEZZB6+vbu05NVmOc+i5TdWPSs2jIr+3dTlVaghHABAGGqdA207D92AABoCVagAIAwhHABAMigSiHchidQK1koIgY83eLI3vJfEQ/U9pYmbEXZtlR7nuOzeJOfIhJ9IhKULK0o2TfdtKJk33T73qsiVqAAgDAn1XyWdll+XDCBAgDCjKn5CbTZEPBUYQIFAISJWIGWRVlWygAAFAorUABAGEK4Cd6l6lRntXkfiBvxAF1v2Tar7yI9tDclz6zNVmSERmWtptqjQld59u1RlVBclNT3ZNQ5LPr3xClVmkAJ4QIAkAEhXABAmColETGBAgDCEMIFAAB1sQIFAIQZV/Mr0GlXC9fiyQyLqBFrmeXsIyKjrQxZcZ4auVGZzHmec4+oDF9PfVvvPvN8oHjRec9VGT5vKVaYL8/jaWVocUzVqbfMChQAEKZKEyjXQAEAyIAVKAAgTMRtLJW5BgoAwCmEcAEAQF0Nr0BbUce13WivQoaiJSrDNXUOrV9TZf01GTVu6/3m6T9iLHkfT1HkWb86SitWHp59tjJjuUorUEK4AIAwVboGSggXAIAMmEABAGFO6q0wbta/LCvYlStXas+ePTp27Jj6+/u1dOlSc9srr7xSfX19eu211/TXv/5V27dv12WXXebeJxMoACDMyaA/j+XLl2vDhg1au3atFi1apK1bt2rLli1auHBhcvtLL71UP/vZz7Rs2TItXrxYzz33nJ566il9+MMfdu23TQ0Wvj/f1W3MBe+IC9F5JkyU4UJ5VRIsUvJ8uHW99pSIseT9fstzjKn3YVTpyKKXxPOOL6L0n7XtHudYPGq1mgYHB/W/Ojo0OjTUVF8zazX9h8FBdXR0aKiBvnbu3Knnn39eq1atOt32wgsvaPPmzbr99tsb2ufu3bv1xBNP6Fvf+lbD4yzKdx0AYBpoNnz7j1m8tVptwt+sWZOrnre3t2vx4sXq6+ub0N7X16clS5Y0NOa2tjbVajX9+c9/dh0rEygAIEzkBHrgwAENDg6e/lu9evWk/c2bN08zZ87UwMDAhPaBgQEtWLCgoTF/5Stf0Zw5c9Tb2+s6Vm5jAQCEibiN5dS/7+rqmhDCHR4eNv/N+PjEq5FtbW2T2lKuueYa3Xnnnfr0pz+t119/3TVOJlAAQCENDQ297TXQw4cPa3R0dNJqc/78+ZNWpf9s+fLl2rRpk66++mo9++yz7vERwgUAhIkM4TZiZGREu3btUk9Pz4T2np4ebd++3fx311xzjR5++GFde+21evrppx17fEvDK1CrrF6EiCw664RbvxAiMg7zzB7Om2eMEWUCWyHq4dYeRTn2eoqSEVzWB2TXkzom7yolItu2lSJK+XkrEa1fv16PPfaY+vv7tWPHDt10003q7u7Wxo0bJUnr1q1TV1eXrr/+eklvTp6PPvqovvzlL2vnzp06++yzJUnHjh3T4OBgw/slhAsAKLXe3l7NnTtXa9asUWdnp3bv3q1ly5Zp3759kqTOzk51d3ef3v7mm29We3u7HnjgAT3wwAOn2x9++GGtWLGi4f02fB/ovzTcpV/ESs77i6cq94dGnNsi/sptxHRbgRapmLx3LHlGmYp0H2jRV6BTcR/oEx0dGmnyPtD2Wk3/yXEfaKuwAgUAhIkI4ZYlOacs4wQAoFBYgQIAwkTeB1p0TU+gVgw+tbS1Tkqey2Bvdq7F84J6r0vkec20FQ9yLkp2cpGuRVvKMMaUVrzGUTVlU7xf2BHXXb19eK6vlv2B2mUJjZZlnAAAFAohXABAmCqtQJlAAQBhuAYKAEAGVVqBlmWcAAAUSm61cFNZYN7MPU8d26iss7JmRRaJdQ6Lfm7zrNCTZ1ZkK8JdrThOr9R5sb5TorJZI1YknjsbrG1b+TqcVPOf9SK9j+ohhAsACFOla6CEcAEAyIAVKAAgTEQSUdEv95zCBAoACEMIFwAA1NXwCtSTGRbVh/UrJNVP1LMfPdlfef5KKko92Vbt06vov1jzPIfez0+EMmRJ5rk6iPjes+5siMis9d41EYkQLgAAGVRpAiWECwBABqxAAQBhqpRExAQKAAgTUYlo2k2g3gveeSpKKb88kzeikqIsqfM1Ymyb58PH85R3ubmpvk5TlPMapRXJT5ao94SnhKm33ZMY1Mprc1wDBQAAdRHCBQCE4RooAAAZEMIFAAB1sQIFAIQhhJsQ8UBt74OzPeXsrAxSqw9PmUAvqw/PGPMOYXj6j3ozFyUsk+c4rHPlzTidbqGh1PF431d5Pqw6ap+p/r3fb9Z3reeB2q1ECBcAANRFCBcAEKZKK1AmUABAmHE1f9lnPGIgU4AQLgAAGbACBQCEIYSbMCvPUTilTq53KW1lukW8cN5sY09t36g3lifE0oo3c1Q2q6ePqLF4+ojaPoLndfZmf6aOx1ur2Ps6eMYY0YfF6sPap9Xu+Q6mFu7UYAUKAAhTpftAuQYKAEAGrEABAGEI4QIAkAEhXAAAUFdutXBTS/A8M1/zzlpNKcOvpDyzbctw/ClR4/ZklnozTiOyP1uxzwjWuK3vj4hsW4s3gza1vfd8e/ZZlNfsHxHCBQAgg5NqfgIsy49zQrgAAGTAChQAEKZKSURMoACAMFW6BkoIFwCADHLLwk1tX5ZfFY3yZuh5FCmEYY0lz+xpy0hQPxFSx2+dE2vcEa+zN5vTm52bF+/+vNt7PodRx57qx/rujKi/m+d3UFZVWoESwgUAhOEaKAAAGVRpBco1UAAAMmAFCgAIQwg34QyjvUgPW85T6mG2UaXvWnEOPfv0Jp14SjZayTVeqb5bkVjkfW96Hr4eVa4yop+IcxsV/opIFooo2efl3WfqO8j6rHmTPiNRiQgAANRFCBcAEKZKSURMoACAMFW6BkoIFwCADFiBAgDCEMJNKENGo4e19PZkr0U84FdKv1m8xx6R4Wv1YR3PWUb7uUb73xJte4xtjzrH4pFnKbsyhHQivpyKUg6wHs/DrT191GtPfSd4M3lT2bZW31HfQZGqNIGW4fMOAEDhEMIFAISpUhIREygAIEyVQrhMoACAMONqfgU5HjGQKcA1UAAAMmh4BTrbaLd+aXhqnHozSPOc9a2av6l2KwNuyGj3PGw5qkZsBOt8n2m0f8Ro359o2+seTbHl+WDmqvNms3rOoTebNaL+rreObard6tv6HpsKhHABAMigShMoIVwAADJgBQoACFOl21hYgQIAwowF/XmtXLlSe/bs0bFjx9Tf36+lS5fW3f7SSy9Vf3+/jh07pj/+8Y+6+eab3ftkAgUAlNry5cu1YcMGrV27VosWLdLWrVu1ZcsWLVy4MLn9e97zHj399NPaunWrFi1apHXr1um+++7TZz7zGdd+29TgLTcrXN1KJxJtw8a2x412T9aqta0VCrB+OdSM9gWJtnca2x4w2v9ktB9JtKXqxkq+c1Kv3dO3lelnnauzjfbU6/yKsW3q/VNvLM1uK/mPvyyJDlMpIvPVu70nU9absevN/E1tb9W2tbLYreNMZdZa2bZWH//NaI9Qq9U0ODioxR0dOjpk3YvQmDm1mnYNDqqrq0tD/9DX8PCwTpyY/O2wc+dOPf/881q1atXpthdeeEGbN2/W7bffPmn7u+66S1dccYUuuuii023f+9739KEPfUhLlixpeJysQAEAYU4G/UnSgQMHNDg4ePpv9erVk/bX3t6uxYsXq6+vb0J7X1+fORl+9KMfnbT9M888o4svvlgzZzaeGkQSEQCgkFIr0H82b948zZw5UwMDAxPaBwYGtGBBKnYoLViwILl9e3u75s2bp0OHDjU0PiZQAECYk2r+8sapFejQ0NCECbSe8fGJVyPb2tomtb3d9qn2ephAAQBhpvo2lsOHD2t0dHTSanP+/PmTVpmnHDp0KLn9yMiI3njjjYb33fAEaiUEp8qzSekHJed5wTXqviErOSB1wd96oLSVFPW60Z76fWWdKyu5Jk/Wr8kjRrunlGGeD2aO6rsVyUKefbai7J93n57Pvvd7wto+lbzj7Tsiuci7TyvpKJUwNMfYNp17OjWmuhLRyMiIdu3apZ6eHm3evPl0e09Pj5588snkv9mxY4c+9alPTWi77LLL1N/fr9HR0Yb3TRIRAKDU1q9frxtvvFErVqzQBRdcoPXr16u7u1sbN26UJK1bt06PPPLI6e03btyoc889V/fee68uuOACrVixQjfccIPuuece134J4QIAwrSiFm5vb6/mzp2rNWvWqLOzU7t379ayZcu0b98+SVJnZ6e6u7tPb793714tW7ZM3/nOd3TLLbfo1Vdf1Ze+9CX95Cc/ce234ftANxntnhCuFdqMuOfR+/QSa+n9TqP93ERbOr9LetVof9FoT0XpjxrbWucw4qk4UaFKz32TeYZwLWW4r7MKIdyoey+tex6LEsL13Ncp2WHZ1GUkbwj3m0Z7hFP3gf77jg79vybvA/13tZr+MDiojo6OhpOIWoEQLgAAGRDCBQCEqdLjzBqeQP/L8nT7id50+9cSbVZo01oGe06i1Yc3O9cKef7V0YcVfvU8ODwqqzjqvHh4MoWL9ADqPDN/85R36H2qeR8S7X0wdcRYIkr5WePzhAWtsplfMdrzDOGeEnkfaNERwgUAIANCuACAMFV6HigTKAAgTJWugRLCBQAgA1agAIAwczo6mg7BzunoCBlL3houpAAAgGX27Nl6+eWX1dnZGdLfwYMHdd555yUfYVYUTKAAgBCzZ8/WrFnWjTs+J06cKPTkKTGBAgCQCUlEAABkwAQKAEAGTKAAAGTABAoAQAZMoAAAZMAECgBABkygAABk8P8BQlp40kA/PPgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_images = len(samples)\n",
    "\n",
    "if n_images != 1:\n",
    "    fig, axs = plt.subplots(1, n_images, figsize = (8, 4))\n",
    "\n",
    "    for i in range(n_images): \n",
    "        axs[i].imshow(x[i].cpu().reshape(img_size, img_size), cmap = \"hot\")\n",
    "        axs[i].axis(\"off\")\n",
    "else: \n",
    "    plt.imshow(samples.cpu().reshape(img_size, img_size), cmap = \"hot\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.colorbar(fraction = 0.046)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2728, device='cuda:0')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euler_samples.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
